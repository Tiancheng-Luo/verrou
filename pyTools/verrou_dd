#!/bin/sh
''''exec python3 -u "$0" "$@" #'''
# This hack is an ugly but portable alternative to #!/usr/bin/env -S python3 -u

import subprocess
import sys
import os
import shutil
#import md5
import hashlib
import copy
from valgrind import DD
import traceback
import shutil
import signal
import math
import time

def failure():
    sys.exit(42)

nbRUN=5
try:
    nbRUN = int(os.environ["VERROU_DD_NRUNS"])
except KeyError:
    pass

maxNbPROC=None
try:
    maxNbPROC = int(os.environ["VERROU_DD_NUM_THREADS"])
except KeyError:
    pass

ddAlgo="rddmin"
try:
    algo = os.environ["VERROU_DD_ALGO"]
    if algo in ["ddmax","rddmin"]:
        ddAlgo=algo
    else:
        print("incorrect VERROU_DD_ALGO env variable")
        failure()
except KeyError:
    pass

rddminVariant="d"
try:
    algo=os.environ["VERROU_DD_RDDMIN"]
    if algo in ["s", "stoch", "d", "dicho", "", "strict"]:
        if algo in ["s", "stoch"]:
            rddminVariant="s"
        if algo in ["d", "dicho"]:
            rddminVariant="d"
        if algo in ["","strict"]:
            rddminVariant=""
    else:
        print("incorrect VERROU_DD_RDDMIN env variable")
        failure()
except KeyError:
    pass

if ddAlgo=="rddmin":
    ddAlgo=rddminVariant+ddAlgo

def exponentialRange(nbRun):
    tab=[int(nbRun / (2**i)) for i in range(1+int(math.floor(math.log(nbRun,2)))) ]
    tab.reverse()
    return tab


param="exp"
try:
    param=os.environ["VERROU_DD_RDDMIN_TAB"]
except KeyError:
    pass

rddMinTab=None
if param=="exp":
    rddMinTab=exponentialRange(nbRUN)
if param=="all":
    rddMinTab=range(nbRUN)
if param=="single":
    rddMinTab=[nbRUN]

if rddMinTab==None and "VERROU_DD_RDDMIN_TAB"in os.environ:
    print ("Invalid VERROU_DD_RDDMIN_TAB env variable")
    failure()



param="half"
try:
    param=os.environ["VERROU_DD_DICHO_TAB"]
except KeyError:
    pass

splitTab=None
if param=="exp":
    splitTab=exponentialRange(nbRUN)
if param=="all":
    splitTab=range(nbRUN)
if param=="single":
    splitTab=[nbRUN]
if param=="half":
    splitTab=[ int(math.ceil(nbRUN / 2.))]
if param in [str(i) for i in range(1, nbRUN+1) ]:
    splitTab=[int(param)]
if splitTab==None and "VERROU_DD_DICHO_TAB"in os.environ:
    print ("Invalid VERROU_DD_DICHO_TAB env variable")
    failure()


splitGranularity=2
try:
    splitGranularity = int(os.environ["VERROU_DD_DICHO_GRANULARITY"])
except KeyError:
    pass


ddSymOrLine="line"
try:
    sym = os.environ["VERROU_DD_SYM"]
    ddSymOrLine="sym"
except KeyError:
    pass


ddQuiet=False
try:
    ddQuiet = os.environ["VERROU_DD_QUIET"]
    ddQuiet=True
except KeyError:
    pass



def printEnvDoc():
    print("""List of en variable :
    VERROU_DD_NRUNS : int (default:5)
    VERROU_DD_NUM_THREADS : int (default None)
    VERROU_DD_ALGO : in ["ddmax", "rddmin"] (default "rddmin")
    VERROU_DD_RDDMIN : in ["s", "stoch", "dicho" ,"d", "strict",""] (default "d")
    VERROU_DD_RDDMIN_TAB : in ["exp", "all" ,"single"] (default "exp")
    VERROU_DD_DICHO_TAB : in ["exp", "all" ,"single", "half"] or int (default "half")
    VERROU_DD_DICHO_GRANULARITY : int
    VERROU_DD_QUIET : set or not (default not)
    VERROU_DD_SYM : set or not (default not)
    """)



def runCmdAsync(cmd, fname, envvars=None):
    """Run CMD, adding ENVVARS to the current environment, and redirecting standard
    and error outputs to FNAME.out and FNAME.err respectively.

    Returns CMD's exit code."""
    if envvars is None:
        envvars = {}

    with open("%s.out"%fname, "w") as fout:
        with open("%s.err"%fname, "w") as ferr:
            env = copy.deepcopy(os.environ)
            for var in envvars:
                env[var] = envvars[var]
            return subprocess.Popen(cmd, env=env, stdout=fout, stderr=ferr)

def getResult(subProcess):
    subProcess.wait()
    return subProcess.returncode


def runCmd(cmd, fname, envvars=None):
    """Run CMD, adding ENVVARS to the current environment, and redirecting standard
    and error outputs to FNAME.out and FNAME.err respectively.

    Returns CMD's exit code."""

    return getResult(runCmdAsync(cmd,fname,envvars))



class verrouTask:

    def __init__(self, prefix,deltas, refDir,runCmd, cmpCmd,nbRun, typeRun="exclude"):
        self.dirname=os.path.join(prefix, md5Name(deltas))
        self.refDir=refDir
        self.runCmd=runCmd
        self.cmpCmd=cmpCmd
        self.nbRun=nbRun
        self.FAIL=DD.DD.FAIL
        self.PASS=DD.DD.PASS
        self.typeRun=typeRun
        self.subProcessRun={}

        if not os.path.exists(self.dirname):
            os.makedirs(self.dirname)
            if self.typeRun=="exclude":
                genExcludeFile(self.refDir, self.dirname, deltas)
            if self.typeRun=="source":

                with open(os.path.join(self.dirname,"dd.source"), "w") as f:
                    f.write("__unknown__\t0\n")
                    for d in deltas:
                        f.write(d)
        print(self.dirname,end="")

    def nameDir(self,i):
        return  os.path.join(self.dirname,"dd.run%i" % (i+1))

    def mkdir(self,i):
         os.mkdir(self.nameDir(i))
    def rmdir(self,i):
        shutil.rmtree(self.nameDir(i))

    def runOneSample(self,i):
        rundir= self.nameDir(i)
        env={}
        if self.typeRun=="exclude":
            env={"VERROU_EXCLUDE": os.path.join(self.dirname,"dd.exclude")}
        if self.typeRun=="source":
            env={"VERROU_SOURCE":  os.path.join(self.dirname,"dd.source")}

        self.subProcessRun[i]=runCmdAsync([self.runCmd, rundir],
                                          os.path.join(rundir,"dd.run"),
                                          env)

    def cmpOneSample(self,i):
        rundir= self.nameDir(i)
        if self.subProcessRun[i]!=None:
            getResult(self.subProcessRun[i])
        retval = runCmd([self.cmpCmd, self.refDir, rundir],
                        os.path.join(rundir,"dd.compare"))

        with open(os.path.join(self.dirname, rundir, "returnVal"),"w") as f:
            f.write(str(retval))
        if retval != 0:
            print("FAIL(%d)" % i)
            return self.FAIL
        else:
            return self.PASS

    def sampleToComputeToGetFailure(self, nbRun):
        """Return the list of samples which have to be computed to perforn nbRun Success run : None mean Failure [] Mean Success """
        listOfDir=[runDir for runDir in os.listdir(self.dirname) if runDir.startswith("dd.run")]
        done=[]
        for runDir in listOfDir:
            status=int((open(os.path.join(self.dirname, runDir, "returnVal")).readline()))
            if status!=0:
                return None
            done+=[runDir]

        res= [x for x in range(nbRun) if not ('dd.run'+str(x+1)) in done]
        return res

    def run(self):
        workToDo=self.sampleToComputeToGetFailure(self.nbRun)
        if workToDo==None:
            print(" --(cache) -> FAIL")
            return self.FAIL

        if len(workToDo)!=0:
            print(" --( run )-> ",end="",flush=True)

            if maxNbPROC==None:
                returnVal=self.runSeq(workToDo)
            else:
                returnVal=self.runPar(workToDo)

            if(returnVal==self.PASS):
                print("PASS(+" + str(len(workToDo))+"->"+str(self.nbRun)+")" )
            return returnVal
        print(" --(cache)-> PASS("+str(self.nbRun)+")")
        return self.PASS

    def runSeq(self,workToDo):

        for run in workToDo:
            self.mkdir(run)
            self.runOneSample(run)
            retVal=self.cmpOneSample(run)

            if retVal=="FAIL":
                return self.FAIL
        return self.PASS

    def runPar(self,workToDo):

        for run in workToDo:
            self.mkdir(run)
            self.runOneSample(run)
        for run in workToDo:
            retVal=self.cmpOneSample(run)

            if retVal=="FAIL":
                return self.FAIL

        return self.PASS


def md5Name(deltas):
    copyDeltas=copy.copy(deltas)
    copyDeltas.sort()
    return hashlib.md5(("".join(copyDeltas)).encode('utf-8')).hexdigest()


def prepareOutput(dirname):
     shutil.rmtree(dirname, ignore_errors=True)
     os.makedirs(dirname)

def genExcludeFile(ref, dest, include):
    """Generate the dd.exclude and dd.include file in rep dest from the dd.exclude (coming from ref) and include tab (usually called deltas)"""

    if ref==None and include==None:
        open(os.path.join(dest,"dd.exclude"),"w")
        return

    with open(os.path.join(ref,"dd.exclude"), "r") as f:
        excludes = f.readlines()
    with open(os.path.join(dest,"dd.include"), "w") as f:
        for d in include:
            excludes.remove(d)
            f.write(d)
    with open(os.path.join(dest,"dd.exclude"), "w") as f:
        for line in excludes:
            f.write(line)

def mergeList(dirname, name="dd.exclude"):
    """merge the file name.$PID into a uniq file called name """
    listOfExcludeFile=[ x for x in os.listdir(dirname) if x.startswith(name+".")]
    if len(listOfExcludeFile)<1:
        print("The generation of exclusion/source files failed")
        failure()

    with open(os.path.join(dirname,listOfExcludeFile[0]), "r") as f:
        excludeMerged=f.readlines()

    for excludeFile in listOfExcludeFile[1:]:
        with open(os.path.join(dirname,excludeFile), "r") as f:
            for line in f.readlines():
                if line not in excludeMerged:
                    excludeMerged+=[line]
    with open(os.path.join(dirname, name), "w" )as f:
        for line in excludeMerged:
            f.write(line)


def symlink(src, dst):
    if os.path.lexists(dst):
        os.remove(dst)
    os.symlink(src, dst)


class DDvr(DD.DD):
    def __init__(self, run, compare, prefix):
        DD.DD.__init__(self)
        self.run_ = run
        self.compare_ = compare
        self.cache_outcomes = False
        self.prefix_ = os.path.join(os.getcwd(),prefix)
        self.ref_ = os.path.join(self.prefix_, "ref")

        prepareOutput(self.ref_)
        self.reference()
        self.index=0

    def checkReference(self):
        retval = runCmd([self.compare_,self.ref_, self.ref_],
                        os.path.join(self.ref_,"checkRef"))
        if retval != 0:
            print("FAILURE: the reference is not valid ")
            print("Suggestions:")
            print("\t1) check the correctness of the %s script"%self.compare_)
            print("\t2) if your code contains C++ code (libraries included), check the presence of the valgrind option --demangle=no in the run script")

            print("Files to analyze:")
            print("\t run output: " +  os.path.join(self.ref_,"dd.out") + " " + os.path.join(self.ref_,"dd.err"))
            print("\t cmp output: " +  os.path.join(self.ref_,"checkRef.out") + " "+ os.path.join(self.ref_,"checkRef.err"))
            failure()

    def testWithLink(self, deltas, linkname):
        #by default the symlinks are generated when the test fail
        testResult=self._test(deltas)
        dirname = os.path.join(self.prefix_, md5Name(deltas))
        symlink(dirname, os.path.join(self.prefix_,linkname))
        return testResult

    def report_progress(self, c, title):
        if not ddQuiet:
            super().report_progress(c,title)

    def configuration_found(self, kind_str, delta_config,verbose=True):
        if verbose:
            print("%s (%s):"%(kind_str,self.coerce(delta_config)))
        self.testWithLink(delta_config, kind_str)

    def run(self, deltas=None, algo=None, granularity=None):
        if deltas==None:
            deltas=self.getDelta0()

        resConf=None
        if algo=="rddmin":
            resConf = self.RDDMin(deltas)
        if algo.startswith("srddmin"):
            resConf= self.SRDDMin(deltas)
        if algo.startswith("drddmin"):
            resConf = self.DRDDMin(deltas,granularity=granularity)
        if algo=="ddmax":
            resConf= self.DDMax(deltas)
        else:
            if resConf!=None:
                flatRes=[c  for conf in resConf for c in conf]
                cmp= [delta for delta in deltas if  delta not in flatRes ]
                self.configuration_found("rddmin-cmp", cmp)

        return resConf

    def DDMax(self, deltas):
        res=self.verrou_dd_max(deltas)
        cmp=[delta for delta in deltas if delta not in res]
        self.configuration_found("ddmax", cmp)
        self.configuration_found("ddmax-cmp", res)

        return cmp

    def RDDMin(self, deltas,nbRun=nbRUN):
        ddminTab=[]
        testResult=self._test(deltas)
        if testResult!=self.FAIL:
            self.deltaFailedMsg(deltas)

        while testResult==self.FAIL:
            conf = self.verrou_dd_min(deltas,nbRun)

            ddminTab += [conf]
            self.configuration_found("ddmin%d"%(self.index), conf)
            #print("ddmin%d (%s):"%(self.index,self.coerce(conf)))

            #update deltas
            deltas=[delta for delta in deltas if delta not in conf]
            testResult=self._test(deltas,nbRun)
            self.index+=1
        return ddminTab

    def splitDeltas(self, deltas,nbRun=nbRUN, granularity=2):
        if self._test(deltas,nbRUN)==self.PASS:
            return [] #short exit

        res=[] #result : set of smallest (each subset with repect with granularity lead to success)

        #two lists which contain tasks
        # -the fail status is known
        toTreatFailed=[deltas]
        # -the status is no not known
        toTreatUnknown=[]

        #name for progression
        algo_name="splitDeltas"

        def treatFailedCandidat(candidat):
            #treat a failing configuration
            self.report_progress(candidat, algo_name)

            # create subset
            cutSize=min(granularity, len(candidat))
            ciTab=self.split(candidat, cutSize)

            cutAbleStatus=False
            for i in range(len(ciTab)):
                ci=ciTab[i]
                #test each subset
                status=self._test(ci ,nbRun)
                if status==self.FAIL:
                    if len(ci)==1:
                        #if the subset size is one the subset is a valid ddmin : treat as such
                        self.configuration_found("ddmin%d"%(self.index), ci)
                        #print("ddmin%d (%s):"%(self.index,self.coerce(ci)))
                        self.index+=1
                        res.append(ci)
                    else:
                        #insert the subset in the begin of the failed task list
                        toTreatFailed.insert(0,ci)
                        #insert the remaining subsets to the unknown task list
                        tail= ciTab[i+1:]
                        tail.reverse() # to keep the same order
                        for cip in tail:
                            toTreatUnknown.insert(0,cip)
                        return
                    cutAbleStatus=True
            #the failing configuration is failing
            if cutAbleStatus==False:
                res.append(candidat)

        def treatUnknownStatusCandidat(candidat):
            #test the configuration : do nothing in case of success and add to the failed task list in case of success
            self.report_progress(candidat, algo_name+ "(unknownStatus)")
            status=self._test(candidat, nbRun)
            if status==self.FAIL:
                toTreatFailed.insert(0,candidat)
            else:
                pass

        # loop over tasks
        while len(toTreatFailed)!=0 or len(toTreatUnknown)!=0:

            unknownStatusSize=len(deltas) #to get a max
            if len(toTreatUnknown)!=0:
                unknownStatusSize=len(toTreatUnknown[0])

            if len(toTreatFailed)==0:
                treatUnknownStatusCandidat(toTreatUnknown[0])
                toTreatUnknown=toTreatUnknown[1:]
                continue

            #select the smallest candidat : in case of equality select a fail
            toTreatCandidat=toTreatFailed[0]
            if  len(toTreatCandidat) <= unknownStatusSize:
                cutCandidat=toTreatCandidat
                toTreatFailed=toTreatFailed[1:]
                treatFailedCandidat(cutCandidat)
            else:
                treatUnknownStatusCandidat(toTreatUnknown[0])
                toTreatUnknown=toTreatUnknown[1:]
        return res

    def SsplitDeltas(self, deltas,runTab=splitTab ,granularity=2):
        #apply splitDeltas recussivly with increasing sample number (runTab)
        #remarks the remain treatment do not respect the binary split structure

        #name for progression
        algo_name="ssplitDelta"

        currentSplit=[deltas]
        for run in runTab:
            nextCurrent=[]
            for candidat in currentSplit:
                if len(candidat)==1:
                    nextCurrent.append(candidat)
                    continue
                self.report_progress(candidat,algo_name)
                res=self.splitDeltas(candidat,run, granularity)
                nextCurrent.extend(res)

            #the remainDeltas in recomputed from the wall list (indeed the set can increase with the apply )
            flatNextCurrent=[flatItem  for nextCurrentItem in nextCurrent for flatItem in nextCurrentItem]
            remainDeltas=[delta for delta in deltas if delta not in flatNextCurrent ]

            #apply split to remainDeltas
            self.report_progress(remainDeltas,algo_name)
            nextCurrent.extend(self.splitDeltas(remainDeltas, run, granularity))

            currentSplit=nextCurrent

        return currentSplit

    def DRDDMin(self, deltas, SrunTab=rddMinTab, dicRunTab=splitTab, granularity=2):
        #name for progression
        algo_name="DRDDMin"

        #assert with the right nbRun number
        nbRun=SrunTab[-1]
        testResult=self._test(deltas,nbRun)
        if testResult!=self.FAIL:
            self.deltaFailedMsg(deltas)

        #apply dichotomy
        candidats=self.SsplitDeltas(deltas,dicRunTab, granularity)
        print("Dichotomy split done")

        res=[]
        for candidat in candidats:
            if len(candidat)==1: #is a valid ddmin
                res+=[candidat]
                deltas=[delta for delta in deltas if delta not in candidat]
            else:
                self.report_progress(candidat, algo_name)
                #we do not known id candidat is a valid ddmin (in case of sparse pattern)
                resTab=self.SRDDMin(candidat,SrunTab)
                for resMin in resTab:
                    res+=[resMin] #add to res
                    deltas=[delta for delta in deltas if delta not in resMin] #reduce search space
        print("Dichotomy split analyze done")

        #after the split filter a classic (s)rddmin is applied
        testResult=self._test(deltas,nbRun)
        if testResult!=self.FAIL:
            return res
        else:
            return res+self.SRDDMin(deltas, SrunTab)



    def SRDDMin(self, deltas,runTab=rddMinTab):
        #name for progression
        algo_name="SRDDMin"
        #assert with the right nbRun number
        nbRun=runTab[-1]
        testResult=self._test(deltas,nbRun)
        if testResult!=self.FAIL:
            self.deltaFailedMsg(deltas)

        ddminTab=[]

        #increasing number of run
        for run in runTab:
            testResult=self._test(deltas,run)

            #rddmin loop
            while testResult==self.FAIL:
                self.report_progress(deltas, algo_name)
                conf = self.verrou_dd_min(deltas,run)
                if len(conf)!=1:
                    #may be not minimal due to number of run)
                    for runIncValue in [x for x in runTab if x>run ]:
                        conf = self.verrou_dd_min(conf,runIncValue)
                        if len(conf)==1:
                            break

                ddminTab += [conf]
                self.configuration_found("ddmin%d"%(self.index), conf)
                #print("ddmin%d (%s):"%(self.index,self.coerce(conf)))
                self.index+=1
                #update search space
                deltas=[delta for delta in deltas if delta not in conf]
                #end test loop of rddmin
                testResult=self._test(deltas,nbRun)

        return ddminTab

    #Error Msg
    def deltaFailedMsg(self,delta):
        print("FAILURE: nothing to debug (the run with all symbols activated succeed)")
        print("Suggestions:")
        print("\t1) check the correctness of the %s script : the failure criteria may be too large"%self.compare_)
        print("\t2) check if the number of samples VERROU_DD_NRUNS is sufficient ")
        print("\t3) if your code contains C++ code (libraries included), check the presence of the valgrind option --demangle=no in the run script")

        dirname = md5Name(delta)
        print("Directory to analyze: %s"%dirname)
        failure()

    def allDeltaFailedMsg(self,deltas):
        print ("FAILURE: when verrou perturbs all parts of the program, its output is still detected as stable.")
        print ("Suggestions:")
        print ("\t1) check if the number of samples VERROU_DD_NRUNS is sufficient")
        print ("\t2) check the correctness of the %s script : the failure criteria may be too large"%self.compare_)
        print ("\t3) set the env variable VERROU_DD_UNSAFE : be careful it is realy unsafe")

        dirname = md5Name(delta)
        print("Directory to analyze: %s"%dirname)
        failure()


    def noDeltaSucceedMsg(self,deltas=[]):
        print("FAILURE: the comparison between verrou with activated symbols in nearest mode (ref) and verrou without activated symbols failed")

        print("Suggestions:")
        print("\t1) check the libm library is correctly excluded")
        print("\t2) check if reproducibilty discrepancies are larger than the failure criteria of the script %s"%self.compare_)
        failure()



class DDsym(DDvr):
    def __init__(self, run, compare, prefix="dd.sym"):
        DDvr.__init__(self, run, compare, prefix)
        mergeList(self.ref_,"dd.exclude")
        self.checkReference()

    def getDelta0(self):
        with open(os.path.join(self.ref_,"dd.exclude"), "r") as f:
            deltas = f.readlines()
            return deltas

    def reference(self):
        dirname = self.ref_
        prepareOutput(dirname)

        retval = runCmd([self.run_, dirname],
                        os.path.join(dirname,"dd"),
                        {"VERROU_ROUNDING_MODE": "nearest",
                         "VERROU_MCA_MODE": "ieee",
                         "VERROU_GEN_EXCLUDE":   os.path.join(dirname,"dd.exclude.%%p")})
        assert retval == 0, "Error during reference run"


    def _test(self, deltas,nbRun=nbRUN):

        vT=verrouTask(self.prefix_,deltas, self.ref_,self.run_, self.compare_ ,nbRun, "exclude")
        return vT.run()

    def coerce(self, config):
        return "\n  " + "  ".join(config)





class DDline(DDvr):
    def __init__(self, run, compare, prefix="dd.line"):
        DDvr.__init__(self, run, compare, prefix)
        mergeList(self.ref_,"dd.source")
        self.checkReference()

    def reference(self):
        dirname = self.ref_
        retval = runCmd([self.run_, dirname],
                        os.path.join(dirname,"dd"),
                        {"VERROU_ROUNDING_MODE": "nearest",
                         "VERROU_MCA_MODE": "ieee",
                         "VERROU_GEN_SOURCE":    os.path.join(dirname,"dd.source.%%p")})
        assert retval == 0, "Error during ddline reference run"

    def getDelta0(self):
        with open(os.path.join(self.ref_ ,"dd.source"), "r") as f:
            return f.readlines()

    def _test(self, deltas,nbRun=nbRUN):
        vT=verrouTask(self.prefix_, deltas, self.ref_,self.run_, self.compare_ ,nbRun, "source")
        return vT.run()

    def coerce(self, config):
        return  "\n  " + "\n  ".join(["%s:%d (%s)" % e for e in
                                      [(col[0], int(col[1]), col[2]) for col in
                                       [(l.strip()+"\t\t").split("\t") for l in config]]])







def main(run, compare,algoSearch="ddmax"):
    if ddSymOrLine=="line":
        dd = DDline(run, compare)
    if ddSymOrLine=="sym":
        dd = DDsym(run,compare)
    dd.run(algo=algo, granularity=splitGranularity)
    return


def usageCmd():
    print("Usage: "+ sys.argv[0] + " runScript cmpScript")

def checkScriptPath(fpath):
    if os.path.isfile(fpath) and os.access(fpath, os.X_OK):
        return os.path.abspath(fpath)
    else:
        print("Invalid Cmd:"+str(sys.argv))
        print(fpath + " should be executable")
        usageCmd()
        failure()

class exec_stat:
    def __init__(self):
        self.timeInit()

    def terminate(self):
        self.timeEnd()
        self.printElapsed(int(self.end- self.start))
        self.printNbRun()

    def timeInit(self):
        self.start = time.time()

    def timeEnd(self):
        self.end = int(time.time())

    def printElapsed(self,duration):
        s= duration % 60
        rm= duration //60
        m=rm%60
        rh=rm//60
        h=rh%24
        rd=rh//24
        print ("\nElapsed Time: %id %ih %imin %is   "%(rd,h,m,s) )

    def isNew(self, filename):
        return ((os.stat(filename).st_mtime) > self.start)

    def printNbRun(self, dirName="."):
        import glob
        if ddSymOrLine=="sym":
            runSymTab=glob.glob(dirName+"/dd.sym/*/dd.run*/dd.run.out")
            runSymFilter=[filename for filename in runSymTab if self.isNew(filename)]
            print("sym  search : %i run (with cache included: %i)"%(len(runSymFilter),len(runSymTab)) )

        if ddSymOrLine=="line":
            runLineTab=glob.glob(dirName+"/dd.line/*/dd.run*/dd.run.out")
            runLineFilter=[filename for filename in runLineTab if self.isNew(filename)]
            print("line search : %i run (with cache included: %i)"%(len(runLineFilter),len(runLineTab)) )            

if __name__ == "__main__":
    et=exec_stat()

    if "-h" in sys.argv or "--help" in sys.argv:
        printEnvDoc()
        failure()

    if len(sys.argv)!=3:
        usageCmd()
        failure()

    runScript=checkScriptPath(sys.argv[1])
    cmpScript=checkScriptPath(sys.argv[2])

    main(runScript, cmpScript, algoSearch=ddAlgo)

    et.terminate()
